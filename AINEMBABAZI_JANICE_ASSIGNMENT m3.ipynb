{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CIFAR-10 dataset (ignoring SSL)...\n",
      "Dataset successfully downloaded and saved as cifar-10-python.tar.gz\n",
      "Augmenting data...\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,101,322\n",
      "Trainable params: 1,101,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 240000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "104448/240000 [============>.................] - ETA: 4:52 - loss: 1.7620 - accuracy: 0.3596"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import ssl\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "save_path = \"cifar-10-python.tar.gz\"\n",
    "\n",
    "# Download the file\n",
    "print(\"Downloading CIFAR-10 dataset (ignoring SSL)...\")\n",
    "urllib.request.urlretrieve(url, save_path)\n",
    "print(f\"Dataset successfully downloaded and saved as {save_path}\")\n",
    "\n",
    "data_dir = \"D:\\Current Emerging Trends\\cifar10\"\n",
    "\n",
    "# Function to unpickle CIFAR-10 files\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        data_dict = pickle.load(fo, encoding = 'bytes')\n",
    "    return data_dict\n",
    "\n",
    "# Loading CIFAR-10 dataset from local files\n",
    "def load_cifar10_data(data_dir):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "# CIFAR_10 is set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3 # This is the number of channels (RGB)\n",
    "IMG_ROWS = 32 # This is the image height\n",
    "IMG_COLS = 32 # This is the image width\n",
    "BATCH_SIZE = 128\n",
    "NB_EPOCH = 20\n",
    "NB_CLASSES = 10 # This is the number of output classes (CIFAR-10)\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "NUM_TO_AUGMENT = 5\n",
    "\n",
    "# Loading CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Data Augmentation\n",
    "print(\"Augmenting data...\")\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "# Augmenting a subset of the dataset\n",
    "xtas, ytas = [], []\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    num_aug = 0\n",
    "    x = X_train[i] # selecting one image\n",
    "    x = x.reshape((1,) + x.shape) #reshape to (1, 32, 32, 3)\n",
    "    \n",
    "    for x_aug in datagen.flow(x, batch_size = 1, save_to_dir = None):\n",
    "        if num_aug >= NUM_TO_AUGMENT:\n",
    "            break\n",
    "        xtas.append(x_aug[0])\n",
    "        ytas.append(y_train[i])\n",
    "        num_aug += 1\n",
    "        \n",
    "# Converting augmented data to numpy arrays and append to original training set\n",
    "xtas = np.array(xtas)\n",
    "ytas = np.array(ytas)\n",
    "X_train = np.concatenate((X_train, xtas), axis = 0)\n",
    "y_train = np.concatenate((y_train, ytas), axis = 0)\n",
    "\n",
    "# normalizing the dataset\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# convert to categorical\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "# The Model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# The First Convolutional Block\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same', input_shape = (IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# The Second Convolutional Block\n",
    "model.add(Conv2D (64, (3, 3), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# The summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Fit the dataget\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# This is the old model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = OPTIM,  metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size = BATCH_SIZE, epochs = NB_EPOCH, validation_split = VALIDATION_SPLIT, verbose = VERBOSE)\n",
    "score = model.evalaute(X_test, Y_test, batch_size = BATCH_SIZE, verbose = VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"Model compiled successfully\")\n",
    "\n",
    "# The new tarin\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size = BATCH_SIZE), samples_per_epoch = X_train.shape[0], epochs = NB_EPOCH, verbose = VERBOSE)\n",
    "score = model.evaluate(X_test, Y_test, batch_size = BATCH_SIZE, verbose = VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Saving the model\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "# Saving the weights\n",
    "model.save_weights('cifar10_weights.h5', overwrite = True)\n",
    "\n",
    "# plot trainnig history\n",
    "plt.plot(history.history['accuracy'], label = 'Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label = 'Train Loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
